{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/train/筛书判否-历史爆款书籍34本/不受宠？无所谓，杀疯豪门万人跪 (1~20章)-总裁、多重身份、傲慢霸气、复仇、男-有魅力的角色、浪漫、甜蜜、言情、大女主、甜宠.txt', 'data/train/筛书判否-历史爆款书籍34本/不当舔狗后，肥妻她美又飒！ (1~20章)-多重身份、离婚、豪门霸总、真假千金、追妻火葬场、破镜重圆、甜宠、打脸.txt', 'data/train/筛书判否-历史爆款书籍34本/二嫁纨绔：嫡长女她杀疯了 (1~20章)-复仇、重生、傲慢霸气、男-腹黑角色.txt', 'data/train/筛书判否-历史爆款书籍34本/傅总，太太又在给你征婚了 (1~20章)-总裁、契约婚姻、怀孕、秘书、秘密关系.txt', 'data/train/筛书判否-历史爆款书籍34本/分手后，禁欲厉总拿命轻哄！ (1~20章)-裁、复仇、男-腹黑角色.txt', 'data/train/筛书判否-历史爆款书籍34本/前妻难追：战少请自重！ (1~20章)-总裁、离婚、契约婚姻.txt', 'data/train/筛书判否-历史爆款书籍34本/厉总快追，太太前夫又找上门了！ (1~20章)-总裁、离婚、男-有魅力的角色、一夜情、名流、言情、豪门霸总.txt', 'data/train/筛书判否-历史爆款书籍34本/厉总，夫人她不是白月光替身 (1~20章)-总裁、离婚、怀孕、一见钟情、多重身份.txt', 'data/train/筛书判否-历史爆款书籍34本/天价哑妻：夫人带球跑了！ (1~20章)-总裁、离婚、怀孕.txt', 'data/train/筛书判否-历史爆款书籍34本/娇妻难哄：荣少，今天离婚吗 (1~20章)-总裁、离婚、一夜情、名流.txt', 'data/train/筛书判否-历史爆款书籍34本/小祖宗她又野又媚，病娇裴总日日哄 (1~20章)-总裁、离婚、重生、大女主、爽文.txt', 'data/train/筛书判否-历史爆款书籍34本/惹她？疯了！假千金她有千层马甲 (1~20章)-总裁、真假千金、爽文、多重身份、浪漫、大女主、学霸.txt', 'data/train/筛书判否-历史爆款书籍34本/掌上欢：战王盛宠小医妃 (1~20章)-傲慢霸气、复仇、男-腹黑角色.txt', 'data/train/筛书判否-历史爆款书籍34本/搭上季爷后，她被宠翻了！ (1~20章)-总裁、契约婚姻、傲慢霸气、男-腹黑角色、甜蜜、多重身份、复仇、浪漫、男-有魅力的角色、一见钟情.txt', 'data/train/筛书判否-历史爆款书籍34本/新婚夜，残疾大佬站起来了 (1~20章)-总裁、闪婚、契约婚姻、名流、多重身份、甜蜜、浪漫、背叛、三角恋.txt', 'data/train/筛书判否-历史爆款书籍34本/早上离婚成富婆，晚上点一屋男模 (1~20章)-总裁、离婚、欲望情色、男-有魅力的角色、一夜情、医生 男、秘密关系、傲慢霸气、浪漫、都市生活.txt', 'data/train/筛书判否-历史爆款书籍34本/服软？绝不，假千金她是亿万大佬 (1~20章)-总裁、一见钟情、都市生活、男-腹黑角色、男-有魅力的角色.txt', 'data/train/筛书判否-历史爆款书籍34本/活该！人家是满级大佬，你偏要找死 (1~20章)-总裁、多重身份、男-腹黑角色.txt', 'data/train/筛书判否-历史爆款书籍34本/爷！认输吧，夫人黑白两道皆马甲 (1~20章)-复仇、黑手党、杀手、言情、大女主、女王、真假千金、HE、甜宠、爽文.txt', 'data/train/筛书判否-历史爆款书籍34本/皇叔独宠小王妃 (1~20章)-重生、男-腹黑角色、男-有魅力的角色.txt', 'data/train/筛书判否-历史爆款书籍34本/离婚后，傅太太她马甲掉了一地 (1~20章)-总裁、多重身份、傲慢霸气.txt', 'data/train/筛书判否-历史爆款书籍34本/离婚后，她马甲遍全球 (1~20章)-总裁、多重身份、傲慢霸气、离婚、男-腹黑角色、男-有魅力的角色、一夜情、契约婚姻、名流、都市生活.txt', 'data/train/筛书判否-历史爆款书籍34本/离婚后，姚小姐的马甲藏不住了 (1~20章)-总裁、追妻火葬场、甜宠、先婚后爱.txt', 'data/train/筛书判否-历史爆款书籍34本/离婚后，总裁他跪地求复合 (1~20章)-总裁、离婚、背叛.txt', 'data/train/筛书判否-历史爆款书籍34本/离婚后，陆小姐马甲又掉了 (1~20章)-总裁、多重身份、傲慢霸气、离婚、男-腹黑角色、男-有魅力的角色、浪漫、一见钟情.txt', 'data/train/筛书判否-历史爆款书籍34本/离婚后，霍总夜夜跪地哄 (1~20章)-离婚、怀孕、青梅竹马、契约婚姻、总裁.txt', 'data/train/筛书判否-历史爆款书籍34本/离职相亲后，发现我怀了前上司的崽 (1~20章)-总裁、欲望情色、一夜情.txt', 'data/train/筛书判否-历史爆款书籍34本/给战神将军冲喜后，她杀疯了 (1~20章)-古言、契约婚姻、甜蜜、男-有魅力的角色.txt', 'data/train/筛书判否-历史爆款书籍34本/罪爱沉沦，陆少跪地轻哄 (1~20章)-总裁、离婚、都市生活、契约婚姻.txt', 'data/train/筛书判否-历史爆款书籍34本/被小叔抛弃后，我成了男科专家 (1~20章)-总裁、男-腹黑角色、年龄差.txt', 'data/train/筛书判否-历史爆款书籍34本/被迫替嫁后，我成了首富夫人 (1~20章)-闪婚、一夜情、多重身份、总裁、男-腹黑角色.txt', 'data/train/筛书判否-历史爆款书籍34本/裴总别傲娇了，夫人已经签了离婚协议 (1~20章)-总裁、离婚、多重身份、契约婚姻.txt', 'data/train/筛书判否-历史爆款书籍34本/要命！她马甲满级，你惹她干嘛 (1~20章)-总裁、闪婚、甜蜜、男-腹黑角色、傲慢霸气、多重身份.txt', 'data/train/筛书判否-历史爆款书籍34本/霍爷别虐了，夫人她不要你了 (1~20章)-总裁、傲慢霸气、都市生活、欲望情色、浪漫.txt']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "test_data_path = 'data/test'\n",
    "test_file_paths = list()\n",
    "\n",
    "for root, dirs, files in os.walk(test_data_path):\n",
    "    for file in files:\n",
    "        test_file_paths.append(f'{test_data_path}/{file}')\n",
    "\n",
    "print(test_file_paths)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-11T06:28:25.035889Z",
     "start_time": "2025-04-11T06:28:25.031359Z"
    }
   },
   "id": "5f7b80e70a960f6e",
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('data/train/筛书判否-历史爆款书籍34本/不受宠？无所谓，杀疯豪门万人跪 (1~20章)-总裁、多重身份、傲慢霸气、复仇、男-有魅力的角色、浪漫、甜蜜、言情、大女主、甜宠.txt', '\\ufeff    第1章   他找上门来了\\n\\n温聆秀气的眉毛因为紧张紧紧拧在一起，直到看清验孕试纸上的一条杠后，积压多日的担忧终于消散。\\n“砰！”\\n客厅里传来巨响，卫生间的门被大力踢开！\\n她迅速回神，换上一副恐慌的表情看向门边，瞳孔染了一层浓烈的惊惧。\\n进门的男人不耐烦大声吼道：“在厕所里蹲这么久，测出来了吗？怀了没？”\\n温聆浑身都在发抖，清丽的小脸惨白如纸，眼角的红痣此时也黯然失色。\\n眼前的男人犹如一头暴戾的猛兽，随时都可能扑上来将她撕碎。\\n他上前一把钳住她纤细的胳膊，双目赤红，嗓音极度暴戾，“验孕试纸呢？给我看看。”\\n温聆哆嗦着手递给他。\\n男人一看，陡然轻笑一声，笑意却不达眼底，满眼都是危险的戾气。\\n温聆知道这是他发怒的前兆。\\n然而这次他没有对着她大吼出声，而是轻抚她的脸，动作温柔，说的话却是残酷至极，“没关系的宝贝，今天再送你去一次，这次再怀不上，我不介意让你永远留在那里。”\\n ...\n",
      "['!\\n', '\"\\n', '#\\n', '$\\n', '%\\n', '&\\n', \"'\\n\", '(\\n', ')\\n', '*\\n', '+\\n', ',\\n', '-\\n', '--\\n', '.\\n', '..\\n', '...\\n', '......\\n', '...................\\n', './\\n', '.一\\n', '.数\\n', '.日\\n', '/\\n', '//\\n', '0\\n', '1\\n', '2\\n', '3\\n', '4\\n', '5\\n', '6\\n', '7\\n', '8\\n', '9\\n', ':\\n', '://\\n', '::\\n', ';\\n', '<\\n', '=\\n', '>\\n', '>>\\n', '?\\n', '@\\n', 'A\\n', 'Lex\\n', '[\\n', '\\\\\\n', ']\\n', '^\\n', '_\\n', '`\\n', 'exp\\n', 'sub\\n', 'sup\\n', '|\\n', '}\\n', '~\\n', '~~~~\\n', '·\\n', '×\\n', '×××\\n', 'Δ\\n', 'Ψ\\n', 'γ\\n', 'μ\\n', 'φ\\n', 'φ．\\n', 'В\\n', '—\\n', '——\\n', '———\\n', '‘\\n', '’\\n', '’‘\\n', '“\\n', '”\\n', '”，\\n', '…\\n', '……\\n', '…………………………………………………③\\n', '′∈\\n', '′｜\\n', '℃\\n', 'Ⅲ\\n', '↑\\n', '→\\n', '∈［\\n', '∪φ∈\\n', '≈\\n', '①\\n', '②\\n', '②ｃ\\n', '③\\n', '③］\\n', '④\\n', '⑤\\n', '⑥\\n', '⑦\\n', '⑧\\n', '⑨\\n', '⑩\\n', '──\\n', '■\\n', '▲\\n', '\\u3000\\n', '、\\n', '。\\n', '〈\\n', '〉\\n', '《\\n', '》\\n', '》），\\n', '」\\n', '『\\n', '』\\n', '【\\n', '】\\n', '〔\\n', '〕\\n', '〕〔\\n', '㈧\\n', '一\\n', '一.\\n', '一一\\n', '一下\\n', '一个\\n']\n"
     ]
    }
   ],
   "source": [
    "from src.util.read_file import read_file\n",
    "\n",
    "encoding = 'utf-8'\n",
    "test_novels = list[tuple]()\n",
    "\n",
    "for file_path in test_file_paths:\n",
    "    test_novels.append((file_path, read_file(file_path, encoding)))\n",
    "\n",
    "with open('data/stopwords', encoding='utf-8') as _f:\n",
    "    stopwords = _f.readlines()\n",
    "\n",
    "print(str(test_novels[0])[:512], '...')\n",
    "print(stopwords[:128])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-11T06:28:25.051247Z",
     "start_time": "2025-04-11T06:28:25.036898Z"
    }
   },
   "id": "7e564d0970997999",
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LdaModel<num_terms=33475, num_topics=10, decay=0.5, chunksize=2000>\n",
      "Dictionary<33475 unique tokens: ['......', '10', '11', '12', '13']...>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "from src import num_topics, min_p\n",
    "from src.util.preprocess import split_words\n",
    "\n",
    "lda_model = LdaModel.load('model/lda/lda_model.pkl')\n",
    "dictionary = Dictionary.load('model/lda/lda_model.pkl.id2word')\n",
    "\n",
    "\n",
    "def predict_topics(_document: str, _model: LdaModel = lda_model, _dictionary: Dictionary = dictionary, _stopwords: list = None, _num_topics: int = num_topics, _min_p: float = min_p):\n",
    "    if _stopwords is None:\n",
    "        _stopwords = stopwords\n",
    "    topic_dist = _model.get_document_topics(_dictionary.doc2bow(split_words(_document, _stopwords)), minimum_probability =_min_p)\n",
    "    topic_dist = [x[1] for x in topic_dist]\n",
    "    np.pad(topic_dist, (0, _num_topics - len(topic_dist)), mode='constant', constant_values=_min_p)\n",
    "    return topic_dist\n",
    "\n",
    "print(lda_model)\n",
    "print(dictionary)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-11T07:02:45.913183Z",
     "start_time": "2025-04-11T07:02:45.879995Z"
    }
   },
   "id": "d7b03a8c72b04f4b",
   "execution_count": 37
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
